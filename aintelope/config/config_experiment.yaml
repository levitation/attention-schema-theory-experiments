timestamp: ${now:%Y%m%d%H%M%S}      # TODO: currently this applies only to log_dir name, not to checkpoint filename. Checkpoint filename timestamp format is hardcoded in dqn_training.py
experiment_name: experiment
events_fname: events.csv          
checkpoint_dir: checkpoints/
log_dir: outputs/${timestamp}/
experiment_dir: ${log_dir}/${experiment_name}/

trainer_params:
  resume_from_checkpoint: False
  num_workers: 4
  max_epochs: 10
  checkpoint: ${log_dir}/checkpoints/
  device: cpu
  verbose: false

hparams:
  env: savanna-safetygrid-parallel-v1
  env_entry_point: "aintelope.environments.savanna_safetygrid:SavannaGridworldParallelEnv"
  env_type: zoo  
  #env: savanna-safetygrid-sequential-v1
  #env_entry_point: "aintelope.environments.savanna_safetygrid:SavannaGridworldSequentialEnv"
  #env_type: zoo
  model: dqn
  unit_test_mode: False      # is set during tests in order to speed up DQN computations
  agent_id: q_agent
  num_episodes: 5   # TEMP for tests only atm
  traintest_mode: train
  train_episodes: 10 
  test_episodes: 3
  warm_start_steps: 5       # not used at the moment, except for the unit tests
  save_frequency: 1 # how often save a model
  agent_params:
    target_instincts: []
  model_params:
    hidden_sizes: [16,16]
    num_conv_layers: 1
    batch_size: 16
    lr: 0.001
    gamma: 0.99
    tau: 0.05
    eps_last_frame: 800
    eps_last_episode: 8
    eps_start: 1.0
    eps_end: 0.01
    replay_size: 99
  env_params:
    env_experiment: aintelope.aintelope_savanna
    level: 0
    map_max: 13     # used for old AIntelope environment
    map_width: ${hparams.env_params.map_max}   # NB! here it is exclusive max, used for Gridworld environments. Also, this width includes the walls at the border of the game, so 2 units of walls. Therefore, interior is map_width - 2.
    map_height: ${hparams.env_params.map_max}   # NB! here it is exclusive max, used for Gridworld environments. Also, this width includes the walls at the border of the game, so 2 units of walls. Therefore, interior is map_height - 2.
    #
    # to make whole map visible while still agent-centric, set the value to 
    # "max(map_width, map_height) - 3" in case of using Gridworld environments. This is because the map width and height includes walls. The agent always sees its own tile, so the actual radius will be one bigger. Therefore in total 3 units can be substracted.
    render_agent_radius: 10     
    #
    # 0 - off (do not use this setting), 1 - once per experiment run, 2 - once per trial
    # (a trial is a sequence of training episodes separated by env.reset call,
    # but using a same model instance), 3 - once per training episode.
    map_randomization_frequency: 1 
    num_iters: 1000 # duration of a single episode. NB! warm_start_steps will be subtracted from this value
    render_mode: null
    # render_map_max: 5     # this field is currently not used anywhere in code
    #
    amount_agents: 1  
    amount_grass_patches: 2
    amount_water_holes: 0
    amount_danger_tiles: 0
    amount_predators: 0
    enable_homeostasis: False
    sustainability_challenge: False
    amount_gold_deposits: 0
    amount_silver_deposits: 0
    #
    scores:
        DANGER_TILE_SCORE: '{"INJURY": 0}'
        PREDATOR_NPC_SCORE: '{"INJURY": 0}'
        MOVEMENT_SCORE: '{"MOVEMENT": 0}'
        COOPERATION_SCORE: '{"COOPERATION": 0}'   # given to an agent when other agent is eating or drinking
        GOLD_SCORE: '{"GOLD": 0}'
        # SILVER_SCORE: '{"SILVER": 0}'       # unused at the moment
        # food
        FOOD_SCORE: '{"FOOD": 0}'
        FOOD_DEFICIENCY_SCORE: '{"FOOD_DEFICIENCY": 0}'
        FOOD_OVERSATIATION_SCORE: '{"FOOD_OVERSATIATION": 0}'
        # drink
        DRINK_SCORE: '{"DRINK": 0}'
        DRINK_DEFICIENCY_SCORE: '{"DRINK_DEFICIENCY": 0}'
        DRINK_OVERSATIATION_SCORE: '{"DRINK_OVERSATIATION": 0}'
    # food parameters
    FOOD_DEFICIENCY_INITIAL: 0
    FOOD_EXTRACTION_RATE: 1
    FOOD_DEFICIENCY_RATE: -0.2   
    FOOD_OVERSATIATION_LIMIT: 2
    FOOD_GROWTH_LIMIT: 20
    FOOD_REGROWTH_EXPONENT: 1.1
    # drink parameters
    DRINK_DEFICIENCY_INITIAL: 0
    DRINK_EXTRACTION_RATE: 1
    DRINK_DEFICIENCY_RATE: -0.2   
    DRINK_OVERSATIATION_LIMIT: 2
    DRINK_GROWTH_LIMIT: 20
    DRINK_REGROWTH_EXPONENT: 1.1
    #
    # 0 - fixed, 1 - relative, depending on last move, 2 - relative,
    # controlled by separate turning actions.
    observation_direction_mode: 0
    # 0 - fixed, 1 - relative, depending on last move, 2 - relative,
    # controlled by separate turning actions.
    action_direction_mode: 0
    #
    test_death: False      # needed for trainer tests
    seed: 0      # needed for trainer tests

hydra:
  run:
    dir: ${log_dir}/hydra_logs/
