timestamp: ${now:%Y%m%d%H%M%S}
experiment_name: experiment
events_dir: events.csv
checkpoint_dir: checkpoints/
log_dir: outputs/${timestamp}/
experiment_dir: ${log_dir}/${experiment_name}/

trainer_params:
  resume_from_checkpoint: False
  num_workers: 4
  max_epochs: 10
  checkpoint: ${log_dir}/checkpoints/
  device: cpu
  verbose: false

hparams:
  batch_size: 16
  lr: 0.001
  env: savanna-safetygrid-parallel-v1
  env_entry_point: "aintelope.environments.savanna_safetygrid:SavannaGridworldParallelEnv"
  env_type: zoo  
  model: dqn
  unit_test_mode: False      # is set during tests in order to speed up DQN computations
  agent_id: q_agent
  gamma: 0.99
  sync_rate: 10
  replay_size: 99
  eps_last_frame: 1000
  eps_start: 1.0
  eps_end: 0.01
  tau: 0.05
  num_episodes: 10 # how long to train
  episode_length: 1010     # TODO: this parameter seems to be unused
  warm_start_steps: 100
  log_figures_every_n_epochs: 5
  every_n_episodes: 1 # how often save a model
  env_params:
    env_experiment: "experiments.aintelope.food_unbounded"
    num_iters: 200 # duration of a single episode. NB! warm_start_steps will be subtracted from this value
    map_min: 0
    map_max: 5
    render_mode: null
    render_map_max: 5
    amount_agents: 1  
    # amount_grass_patches: 1
    # amount_water_holes: 0
    test_death: False      # needed for trainer tests
    seed: null      # needed for trainer tests
  agent_params:
    target_instincts: []

hydra:
  run:
    dir: ${log_dir}/hydra_logs/
