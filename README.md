# aintelope

We operationalize conjectures from Steven Byrnes’
[“Reverse-engineer human social instincts”](https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8/p/tj8AC3vhTnBywdZoA)
research program and extend existing research into brain-like AI. We simulate
agents with reinforcement learning over selected cue-response patterns in
environments that could give rise to humanl-iike complex behaviors. To do so we
select cue-responses from a pre-existing list of more than 60 candidates for
human affects and instincts from affective neuroscience and other sources
including original patterns. Cue-responses are conjectured to form hierarchies
and the project will start the simulation of lower-level patterns first. We
intend to verify the general principles and the ability of our software to model
and simulate the agents and the environment to a sufficient degree.

Working document:
https://docs.google.com/document/d/1qc6a3MY2_guCZH8XJjutpaASNE7Zy6O5z1gblrfPemk/edit#

## Project setup

### Installation

The project installation is managed via `make` and `pip`. Please see the
respective commanads in the `Makefile`. To setup the environment follow these
steps:

1. Create a virtual python environment: `make venv`
2. Activate the environment: `source venv_aintelope/bin/activate`
3. Install dependencies: `make install`

For development and testing follow (active environment):

1. Install development dependencies: `make install-dev`
2. Install project locally: `make build-local`
3. Run tests: `make tests-local`

### Code formatting

To autoformat python files you can use [`black`](https://github.com/psf/black).
To automatically sort the imports you can run
[`isort .`](https://github.com/PyCQA/isort) from the root level of the project.
Configurations of the formatters can be found in `pyproject.toml`

## Executing `aintelope`

Try `make run-training`. Then look in `aintelope/outputs/memory_records`. (WIP)
There should be two new files named `Record_{current timestamp}.csv` and
`Record_{current timestamp}_plot.png`. The plot will be an image of the path the
agent took during the test episode, using the best agent that the training
produced. Green dots are food in the environment, blue dots are water.

## Logging

The logging level can be controlled via hydra. By adding `hydra.verbose=True`
all loggers will be executed with level `DEBUG`. Alternatively a string or list
of loggers can be provided. See the
[documentation](https://hydra.cc/docs/tutorials/basic/running_your_app/logging/)
for more details.

# Cygwin

If you are a Windows user, note that this project does work fine on linux ubuntu
using Windows wsl2. If you would prefer not to use wsl2, and instead run this
directly on Windows, you will need to figure out how to do that. We have not
managed to get aintelope to build under Windows/Cygwin!

You need at least the following prerequisites:

- Python: Cygwin modules Python 3.7 including python3-devel (but no 3.9+
  available)
- Pytorch: https://github.com/KoichiYasuoka/CygTorch

## Known Issues

- Even with CygTorch pytorch-lightning can't find a Torch version.
